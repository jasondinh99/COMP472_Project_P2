{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a9168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Base Model For Image Classification:\n",
    "class ImageClassificationBase(nn.Module):\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        acc = accuracy(out, labels)  # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()  # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "\n",
    "# CNN Model For Classification:\n",
    "class FaceMaskClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(82944, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "\n",
    "# Extra functions to aid model training and evaluation:\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "#train the model and after every epoch save the model that gives us a validation accuracy >=60%\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        if result['val_acc'] >= 0.60:\n",
    "            # To save a model:\n",
    "            torch.save(model.state_dict(),r\"C:/Users/Axel\\Desktop/newwine/comp 472/project/demo_model.sav\")\n",
    "            return history\n",
    "\n",
    "    print(\"desired accuracy wasnt obtained \")\n",
    "    return history\n",
    "\n",
    "\n",
    "#used to print predicted labels and evaluation such as confusion matrix and f1-score\n",
    "def test(model, test_dl):\n",
    "    list_labels = []  # list of labels (actual class values of images)\n",
    "    list_preds = []  # list of predictions (nn's guesses)\n",
    "\n",
    "    all_preds = []\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # collecting labels and predictions from batches into lists\n",
    "    for batch in test_dl:\n",
    "        images, labels = batch\n",
    "        outputs = model(images)\n",
    "        for i in labels:\n",
    "            list_labels.append(i.item())\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        all_outputs += outputs\n",
    "\n",
    "        all_labels += labels\n",
    "        all_preds += preds\n",
    "\n",
    "        for i in preds:\n",
    "            list_preds.append(torch.max(i).item())\n",
    "\n",
    "    same = 0\n",
    "    not_same = 0\n",
    "\n",
    "    for k in range(len(list_labels)):\n",
    "        if int(list_preds[k]) == int(list_labels[k]):\n",
    "            same += 1\n",
    "        elif int(list_preds[k]) != int(list_labels[k]):\n",
    "            not_same += 1\n",
    "\n",
    "    y_true = list_labels\n",
    "    y_pred = list_preds\n",
    "\n",
    "    print('y_pred: ', y_pred)\n",
    "    print('y_true: ', y_true)\n",
    "\n",
    "    print('****************************************')\n",
    "    print('\\t\\tConfusion Matrix')\n",
    "    print('****************************************')\n",
    "    print('Columns are predictions, rows are labels\\n')\n",
    "\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(cf_matrix)\n",
    "\n",
    "    fn = 0  # False Negative\n",
    "    fp = 0  # False Positive\n",
    "    tp = 0  # True Positive\n",
    "    tn = 0  # True Negative\n",
    "    for c in range(4):  # calculating the above values from the cf_matrix\n",
    "        tp += cf_matrix[c][c]\n",
    "        for r in range(4):\n",
    "            if r != c:\n",
    "                fp += cf_matrix[r][c]\n",
    "        for i in range(4):\n",
    "            if i != c:\n",
    "                fn += cf_matrix[c][i]\n",
    "\n",
    "    for c in range(4):  # calculating the above values from the cf_matrix\n",
    "        fn = 0  # False Negative\n",
    "        fp = 0  # False Positive\n",
    "        tp = 0  # True Positive\n",
    "\n",
    "        tp += cf_matrix[c][c]\n",
    "        for r in range(4):\n",
    "            if r != c:\n",
    "                fp += cf_matrix[r][c]\n",
    "        for i in range(4):\n",
    "            if i != c:\n",
    "                fn += cf_matrix[c][i]\n",
    "\n",
    "        tn = len(list_labels) - fn - fp - tp\n",
    "        print('\\nCLASS #', str(c))\n",
    "\n",
    "        accuracy = (tp + tn)/ (tp + tn + fp + fn)\n",
    "        format_float = \"{:.2f}\".format(accuracy)\n",
    "        print('Accuracy: ', format_float)\n",
    "        precision = tp / (tp+fp)\n",
    "        format_float = \"{:.2f}\".format(precision)\n",
    "        print('Precision: ', format_float)\n",
    "        recall = tp / (tp+fn)\n",
    "        format_float = \"{:.2f}\".format(recall)\n",
    "        print('Recall: ', format_float)\n",
    "        f1_measure = 2 * (precision * recall) / (precision + recall)\n",
    "        format_float = \"{:.2f}\".format(f1_measure)\n",
    "        print('F1_score: ', format_float)\n",
    "\n",
    "    print('\\n\\nTotal (all classes together):')\n",
    "\n",
    "    accuracy = same / (not_same + same)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    print('Precision: ', precision)\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    print('Recall: ', recall)\n",
    "    score = f1_score(y_true, y_pred, average='micro')\n",
    "    print('F1_score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73afedfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you want to train the base modelno\n",
      "tp: 159\n",
      "y_pred:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 3, 1, 0, 3, 0, 0, 1, 0, 0, 0, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 1, 3, 3, 3, 1, 3, 3, 0, 3, 3, 3, 1, 3, 0, 3, 1, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 0, 3, 3, 3, 1, 3, 3, 3, 0, 3, 3]\n",
      "y_true:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "****************************************\n",
      "\t\tConfusion Matrix\n",
      "****************************************\n",
      "Columns are predictions, rows are labels\n",
      "\n",
      "[[40  3  2  5]\n",
      " [ 1 45  0  4]\n",
      " [ 8  1 39  2]\n",
      " [ 7  5  3 35]]\n",
      "tp 159\n",
      "fp 41\n",
      "fn 41\n",
      "\n",
      "CLASS # 0\n",
      "Accuracy:  0.71\n",
      "Precision:  0.71\n",
      "Recall:  0.80\n",
      "F1_score:  0.75\n",
      "\n",
      "CLASS # 1\n",
      "Accuracy:  0.83\n",
      "Precision:  0.83\n",
      "Recall:  0.90\n",
      "F1_score:  0.87\n",
      "\n",
      "CLASS # 2\n",
      "Accuracy:  0.89\n",
      "Precision:  0.89\n",
      "Recall:  0.78\n",
      "F1_score:  0.83\n",
      "\n",
      "CLASS # 3\n",
      "Accuracy:  0.76\n",
      "Precision:  0.76\n",
      "Recall:  0.70\n",
      "F1_score:  0.73\n",
      "\n",
      "\n",
      "Total (all classes together):\n",
      "Accuracy:  0.795\n",
      "Precision:  0.795\n",
      "Recall:  0.795\n",
      "F1_score:  0.795\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # train and test directory\n",
    "    data_dir = r\"C:/Users/Axel/Desktop/newwine/comp 472/project/COMP472_Project/dataset\"\n",
    "    #sample directory\n",
    "    sample_dir = r\"C:/Users/Axel/Desktop/newwine/comp 472/project/COMP472_Project/sample-dataset\"\n",
    "\n",
    "    request = input('do you want to train the base model')\n",
    "\n",
    "    if request == 'yes':\n",
    "        # Preparing the Dataset :\n",
    "        # To prepare a dataset from such a structure, PyTorch provides ImageFolder class which makes the task easy for us\n",
    "        # to prepare the dataset.\n",
    "        # We simply have to pass the directory of our data to it and it provides the dataset which we can use to train the model.\n",
    "\n",
    "        # load the train and test data\n",
    "        # The torchvision.transforms module provides various functionality to preprocess the images,\n",
    "        # here first we resize the image for (150*150) shape and then transforms them into tensors.\n",
    "        dataset = ImageFolder(data_dir, transform=transforms.Compose([\n",
    "            transforms.Resize((150, 150)), transforms.ToTensor()\n",
    "        ]))\n",
    "\n",
    "        # The image label set according to the class index in data.classes.\n",
    "        print(\"Follwing classes are there : \\n\", dataset.classes)\n",
    "\n",
    "        # output:\n",
    "        # Follwing classes are there :\n",
    "        # ['cloth_mask', 'n95_mask', 'no_mask', 'surgical_mask']\n",
    "\n",
    "        # Splitting Data and Prepare Batches:\n",
    "        batch_size = 64\n",
    "        val_size = 246\n",
    "        test_size = 400\n",
    "        train_size = len(dataset) - test_size\n",
    "\n",
    "        train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "        print(f\"Length of Train+validation Data : {len(train_data)}\")\n",
    "        print(f\"Length of test Data : {len(test_data)}\")\n",
    "\n",
    "        train_data, val_data = random_split(train_data, [train_size - val_size, val_size])\n",
    "        print(f\"Length of Train Data : {len(train_data)}\")\n",
    "        print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "        # load the train,validation, and test into batches.\n",
    "        train_dl = DataLoader(train_data, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        val_dl = DataLoader(val_data, batch_size, num_workers=4, pin_memory=True)\n",
    "        test_dl = DataLoader(test_data, batch_size * 2, num_workers=4, pin_memory=True)\n",
    "\n",
    "        model = FaceMaskClassification()\n",
    "\n",
    "        num_epochs = 30\n",
    "        opt_func = torch.optim.Adam\n",
    "        lr = 0.001\n",
    "\n",
    "        # train the model\n",
    "        history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n",
    "\n",
    "        # To restore a model:\n",
    "        model = FaceMaskClassification()\n",
    "        model.load_state_dict(torch.load(r\"C:/Users/Axel/Desktop/newwine/comp 472/project/demo_model.sav\"), strict=False)\n",
    "\n",
    "        # run the model on test\n",
    "        print('\\nEvaluation:')\n",
    "        test(model, test_dl)\n",
    "\n",
    "    elif request == \"no\":\n",
    "        # prepare sample dataset\n",
    "        sample_dataset = ImageFolder(sample_dir, transform=transforms.Compose([\n",
    "            transforms.Resize((150, 150)), transforms.ToTensor()\n",
    "        ]))\n",
    "\n",
    "        sample_dl = DataLoader(sample_dataset, len(sample_dataset), num_workers=4, pin_memory=True)\n",
    "\n",
    "        # To restore a model:\n",
    "        model = FaceMaskClassification()\n",
    "        model.load_state_dict(torch.load(r\"C:/Users/Axel/Desktop/newwine/comp 472/project/finalized_model.sav\"),\n",
    "                              strict=False)\n",
    "\n",
    "        # run the model on sample\n",
    "        test(model, sample_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9524e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
